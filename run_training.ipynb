{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1d7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from decoder_pretrain import DecoderPretrainNet\n",
    "from encoder_pretrain import EncoderPretrainNet\n",
    "from gloss_dminus import GlobalLossDminus\n",
    "from gloss_d import GlobalLossD\n",
    "from dice_loss import DiceLoss\n",
    "from seg_unet import UNet_pretrained, UNet\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import json\n",
    "import statistics\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from training_utils import *\n",
    "from data_augmentation_utils import DataAugmentation\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with open('configs/preprocessing_datasets.json') as config_file:\n",
    "    config_datasets = json.load(config_file)\n",
    "with open('configs/seg_unet_Met.json') as config_file:\n",
    "    config_seg = json.load(config_file)\n",
    "with open('configs/config_encoder.json') as config_file:\n",
    "    config_encoder = json.load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "530a6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataset(config_datasets, config_seg, dataset, total_n_volumes=24, n_volumes=2, \n",
    "                       split_set = 'train',shuffle = False, idx_vols_val = None, return_idx = False) :\n",
    "            \n",
    "    img_dataset = []\n",
    "    mask_dataset = []\n",
    "        \n",
    "    idx_vols = select_random_volumes(total_n_volumes, n_volumes) \n",
    "    if idx_vols_val != None :\n",
    "        assert len(idx_vols_val) + n_volumes <= total_n_volumes\n",
    "        while any(item in idx_vols for item in idx_vols_val) :\n",
    "            idx_vols = select_random_volumes(total_n_volumes, n_volumes) \n",
    "            \n",
    "    count = -1\n",
    "    data = None\n",
    "    for config_dataset in config_datasets :\n",
    "        if config_dataset['Data'] == dataset :  \n",
    "            for path in Path(config_dataset['savedir']+ split_set +'/').rglob('subject_*/'):\n",
    "                \n",
    "                if dataset == 'Metastases' :\n",
    "                    if \"nii.gz\" in str(path) or \".png\" in str(path) :\n",
    "                        continue\n",
    "                    count += 1   \n",
    "                    if count >= n_volumes :\n",
    "                        break\n",
    "                        \n",
    "                    # Add the image and the corresponding mask to the datasets\n",
    "                    for path_image in path.rglob(\"img.nii.gz\") :\n",
    "                        img_dataset.append(path_image)\n",
    "                        print(path_image)\n",
    "                    for path_mask in path.rglob(\"mask.nii.gz\") :\n",
    "                        mask_dataset.append(path_mask)\n",
    "                    \n",
    "                    if split_set == 'train' : \n",
    "                        data = dataset\n",
    "                    \n",
    "                else :\n",
    "                    # We want total path not individual path of images\n",
    "                    if \"nii.gz\" in str(path) or \".png\" in str(path) :\n",
    "                        continue\n",
    "                    count += 1   \n",
    "\n",
    "                    # Different criterion to stop adding train or test volumes\n",
    "                    if split_set == 'test':\n",
    "                        if count >= n_volumes :\n",
    "                            break\n",
    "                    else :\n",
    "                        if count not in idx_vols :\n",
    "                            continue\n",
    "\n",
    "                    # Add the image and the corresponding mask to the datasets\n",
    "                    for path_image in path.rglob(\"img.nii.gz\") :\n",
    "                        img_dataset.append(path_image)\n",
    "                        print(path_image)\n",
    "                    for path_mask in path.rglob(\"mask.nii.gz\") :\n",
    "                        mask_dataset.append(path_mask)\n",
    "    \n",
    "    # initalize the dataset\n",
    "    dataset = TrainDataset(config_seg, img_dataset, mask_dataset, data)\n",
    "    dataset_loader = DataLoader(dataset,\n",
    "                                num_workers=1,\n",
    "                                batch_size=config_seg['batch_size'],\n",
    "                                shuffle=shuffle,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=False)\n",
    "    if return_idx :\n",
    "        return dataset_loader, idx_vols\n",
    "    else :\n",
    "        return dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e12ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, config, volumes, masks, dataset = None):\n",
    "        self.path_volumes = volumes\n",
    "        self.path_masks = masks\n",
    "        #self.n_vols = 1\n",
    "        \n",
    "        for i in range(len(self.path_volumes)):\n",
    "            vol_file = self.path_volumes[i]\n",
    "            mask_file = self.path_masks[i]\n",
    "\n",
    "            volume = nib.load(vol_file).get_fdata()\n",
    "            mask = nib.load(mask_file).get_fdata()\n",
    "            \n",
    "            assert volume.shape == mask.shape\n",
    "\n",
    "            new_img = volume.transpose(2, 0, 1)\n",
    "            new_mask = mask.transpose(2, 0, 1)\n",
    "            \n",
    "            if i == 0: \n",
    "                self.imgs = new_img\n",
    "                self.masks = new_mask\n",
    "            else :\n",
    "                self.imgs = np.concatenate((self.imgs, new_img), axis=0)\n",
    "                self.masks = np.concatenate((self.masks, new_mask), axis=0)\n",
    "                \n",
    "        \n",
    "        if dataset == 'Metastases' :\n",
    "            indexes_tumors_slices = []\n",
    "            for i in range(self.imgs.shape[0]) :\n",
    "                if 1 in self.masks[i] :\n",
    "                    indexes_tumors_slices.append(i)\n",
    "            \n",
    "            self.imgs_tumors = self.imgs[indexes_tumors_slices,:,:]\n",
    "            self.masks_tumors = self.masks[indexes_tumors_slices,:,:]\n",
    "            \n",
    "            indexes = np.arange(0,self.imgs.shape[0], dtype=np.int32)\n",
    "            indexes_healthy = np.delete(indexes,indexes_tumors_slices)\n",
    "            \n",
    "            self.imgs_healthy = self.imgs[indexes_healthy,:,:]\n",
    "            self.masks_healthy = self.masks[indexes_healthy,:,:]\n",
    "            \n",
    "            indexes_balance_healthy = random.sample(range(0, self.imgs_healthy.shape[0]), len(indexes_tumors_slices))\n",
    "            \n",
    "            self.imgs_balance_healthy = self.imgs_healthy[indexes_balance_healthy,:,:]\n",
    "            self.masks_balance_healthy = self.masks_healthy[indexes_balance_healthy,:,:]\n",
    "            \n",
    "            print(self.imgs.shape)\n",
    "            self.imgs = np.concatenate((self.imgs_balance_healthy , self.imgs_tumors ), axis=0)\n",
    "            self.masks = np.concatenate((self.masks_balance_healthy, self.masks_tumors), axis=0)\n",
    "            \n",
    "            print(self.imgs.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.masks[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09c1096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   2,    2,    3],\n",
       "         [  14,   23,    3]],\n",
       "\n",
       "        [[   2,  223,    3],\n",
       "         [1422,   23,  311]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 2)\n",
    "x = torch.tensor([[[2,2,3], [14,23,3]], [[2,223,3], [1422,23,311]]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "642a2578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "223 in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "60824623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "../img_cropped/metastases/test/subject_567/img.nii.gz\n",
      "../img_cropped/metastases/test/subject_7385/img.nii.gz\n",
      "Validation set\n",
      "../img_cropped/metastases/validation/subject_6578/img.nii.gz\n",
      "../img_cropped/metastases/validation/subject_6376/img.nii.gz\n",
      "Training set\n",
      "../img_cropped/metastases/train/subject_1624/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_678/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_1220/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_4250/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_2432/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_1927/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_3442/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_1019/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_1523/img.nii.gz\n",
      "../img_cropped/metastases/train/subject_412/img.nii.gz\n",
      "(3360, 192, 192)\n",
      "(926, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "n_vol_train = config_seg['n_vol_train']\n",
    "n_vol_val = config_seg['n_vol_val']\n",
    "\n",
    "lambda_ = 0.6\n",
    "\n",
    "n_vol_trains = [10]\n",
    "seeds = [0]#, 10, 20, 30, 40, 50]\n",
    "options = ['option_10']#, 'option_2', 'option_3', 'option_4', 'option_5', 'option_6', 'option_7'] \n",
    "losses_unet = [config_seg['loss_unet']] \n",
    "\n",
    "dataset = config_seg['dataset']\n",
    "resize_size = config_seg['resize_size']\n",
    "n_channels = config_seg['n_channels']\n",
    "max_epochs = config_seg['max_epochs']\n",
    "n_classes = config_seg['n_classes']\n",
    "batch_size = config_seg['batch_size']\n",
    "lr = config_seg['lr']\n",
    "weight_pretrained = config_seg['weight_pretrained']\n",
    "\n",
    "save_global_path = config_seg['save_global_path']\n",
    "\n",
    "if dataset == 'Abide':\n",
    "    n_classes = 15\n",
    "    lab = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "    weights = torch.tensor([0.025, 0.075, 0.075, 0.035, 0.035, 0.075, 0.075, 0.075, \n",
    "                                   0.075, 0.075, 0.075, 0.075, 0.075, 0.075, 0.075], dtype=torch.float32)\n",
    "    \n",
    "    total_n_volumes = 24\n",
    "    n_vol_test = 12\n",
    "    \n",
    "elif dataset == 'CIMAS' or dataset == 'ACDC' :\n",
    "    n_classes = 4\n",
    "    lab = [1,2,3]\n",
    "    weights = torch.tensor([0.1, 0.3, 0.3, 0.3], dtype=torch.float32)\n",
    "    \n",
    "    if dataset == 'CIMAS' :\n",
    "        total_n_volumes = 13\n",
    "        n_vol_test = 7\n",
    "    else :\n",
    "        total_n_volumes = 69\n",
    "        n_vol_test = 30\n",
    "        \n",
    "if dataset == 'Metastases':\n",
    "    n_classes = 2\n",
    "    lab = [1]\n",
    "    weights = torch.tensor([0.1, 0.9], dtype=torch.float32)\n",
    "    \n",
    "    total_n_volumes =53\n",
    "    n_vol_test = 2#24\n",
    "    n_vol_val = 2#18\n",
    "        \n",
    "print('Test set')\n",
    "dataset_loader_test = initialize_dataset(config_datasets, config_seg, dataset, total_n_volumes=n_vol_test, \n",
    "                                         n_volumes=n_vol_test, split_set = 'test', \n",
    "                                         shuffle = False)\n",
    "        \n",
    "        \n",
    "\n",
    "data_aug = DataAugmentation()\n",
    "for loss_unet in losses_unet :\n",
    "    run = -1\n",
    "    for seed in seeds :\n",
    "        torch.cuda.empty_cache()\n",
    "        run += 1\n",
    "        torch.manual_seed(seed)\n",
    "        # Load losses Pretrained encoder\n",
    "        for n_vol_train in n_vol_trains:\n",
    "\n",
    "            # Initialization of the datasets\n",
    "\n",
    "            random.seed(seed)\n",
    "            print('Validation set')\n",
    "            random.seed(seed)\n",
    "            \n",
    "            if dataset == 'Metastases' :\n",
    "                dataset_loader_validation = initialize_dataset(config_datasets, config_seg, dataset, \n",
    "                                                           total_n_volumes=total_n_volumes, \n",
    "                                                           n_volumes=n_vol_val, split_set = 'validation', \n",
    "                                                           shuffle = False, return_idx = False)\n",
    "                random.seed(seed)\n",
    "                print('Training set')\n",
    "                dataset_loader_train = initialize_dataset(config_datasets, config_seg, dataset, \n",
    "                                                          total_n_volumes=total_n_volumes, \n",
    "                                                          n_volumes=n_vol_train, split_set = 'train', \n",
    "                                                          shuffle = True)\n",
    "                \n",
    "            else : \n",
    "                dataset_loader_validation, idx_vols_val = initialize_dataset(config_datasets, config_seg, dataset, \n",
    "                                                           total_n_volumes=total_n_volumes, \n",
    "                                                           n_volumes=n_vol_val, split_set = 'train', \n",
    "                                                           shuffle = False, return_idx = True)\n",
    "                random.seed(seed)\n",
    "                print('Training set')\n",
    "                dataset_loader_train = initialize_dataset(config_datasets, config_seg, dataset, \n",
    "                                                          total_n_volumes=total_n_volumes, \n",
    "                                                          n_volumes=n_vol_train, split_set = 'train', \n",
    "                                                          shuffle = True, idx_vols_val = idx_vols_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e99ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d2594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b073807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
